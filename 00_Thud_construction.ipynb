{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc5f067",
   "metadata": {},
   "source": [
    "# Thudbot Scaffold\n",
    "\n",
    "This will be a prototype Thudbot built in jupyter.\n",
    "\n",
    "Steps:\n",
    "1. General setup\n",
    "2. Data collection and Preparation\n",
    "3. SDG with RAGAS to create a golden data set\n",
    "4. Setup the RAG chain (finally)\n",
    "5. Evaluate results with RAGAS\n",
    "6. Refine RAG performance (prompt tuning, retreival methods)\n",
    "\n",
    "Once everything works:\n",
    "- Convert to a standalone Python script\n",
    "- Build or reuse a chatbot front end to run it locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad5c4c3",
   "metadata": {},
   "source": [
    "\n",
    "Naming this 00_ so that it will be the first notebook every time I start a new session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9badc3b1",
   "metadata": {},
   "source": [
    "## Step 1 General setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "182642a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- API Key Status ---\n",
      "OPENAI_API_KEY loaded: True\n",
      "LANGCHAIN_API_KEY loaded: True\n",
      "TAVILY_API_KEY loaded: True\n",
      "RAGAS_API_KEY loaded: False\n",
      "ANTHROPIC_API_KEY loaded: True\n",
      "COHERE_API_KEY loaded: True\n",
      "\n",
      "--- Project Settings Status ---\n",
      "DEBUG mode enabled: True\n",
      "LangSmith Tracing V2 enabled: True\n",
      "LangChain Project Base: None\n",
      "LangChain Project: THUDBOT-CC\n"
     ]
    }
   ],
   "source": [
    "### API key management and environment variables\n",
    "\n",
    "### Reminder: Place .env file inside the root of the project folder so when calling the below from inside the notebook it should find the .env fule and load it inside the notebook environment\n",
    "### PLEASE ADD THIS `.env` FILE TO YOUR PROJECT'S `.gitignore` file before committing and pushing the changes to your remote repo, as it contains API Keys and Secrets in it\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "\n",
    "# --- Verify API Keys ---\n",
    "print(\"--- API Key Status ---\")\n",
    "print(f\"OPENAI_API_KEY loaded: {'OPENAI_API_KEY' in os.environ}\")\n",
    "print(f\"LANGCHAIN_API_KEY loaded: {'LANGCHAIN_API_KEY' in os.environ}\")\n",
    "print(f\"TAVILY_API_KEY loaded: {'TAVILY_API_KEY' in os.environ}\")\n",
    "print(f\"RAGAS_API_KEY loaded: {'RAGAS_API_KEY' in os.environ}\")\n",
    "print(f\"ANTHROPIC_API_KEY loaded: {'ANTHROPIC_API_KEY' in os.environ}\")\n",
    "print(f\"COHERE_API_KEY loaded: {'COHERE_API_KEY' in os.environ}\")\n",
    "\n",
    "# --- Verify General Settings ---\n",
    "print(\"\\n--- Project Settings Status ---\")\n",
    "print(f\"DEBUG mode enabled: {os.environ.get('DEBUG') == 'True'}\")\n",
    "print(f\"LangSmith Tracing V2 enabled: {os.environ.get('LANGCHAIN_TRACING_V2') == 'true'}\")\n",
    "print(f\"LangChain Project Base: {os.environ.get('LANGCHAIN_PROJECT_BASE')}\")\n",
    "print(f\"LangChain Project: {os.environ.get('LANGCHAIN_PROJECT')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09fc64",
   "metadata": {},
   "source": [
    "including nltk, because it worked before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140254c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/family/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/family/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06eb6339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/family/Library/Mobile Documents/com~apple~CloudDocs/AppDev/thudbot/.venv/lib/python3.13/site-packages/pysbd/segmenter.py:66: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  for match in re.finditer('{0}\\s*'.format(re.escape(sent)), self.original_text):\n",
      "/Users/family/Library/Mobile Documents/com~apple~CloudDocs/AppDev/thudbot/.venv/lib/python3.13/site-packages/pysbd/lang/arabic.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  txt = re.sub('(?<={0})\\.'.format(am), '∯', txt)\n",
      "/Users/family/Library/Mobile Documents/com~apple~CloudDocs/AppDev/thudbot/.venv/lib/python3.13/site-packages/pysbd/lang/persian.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  txt = re.sub('(?<={0})\\.'.format(am), '∯', txt)\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "eval_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "eval_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854ab91",
   "metadata": {},
   "source": [
    "## Step 2: Data Collection and Preparation\n",
    "\n",
    "My data is CSV structured, so using code from HW9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89bf5b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_id: TSB-001\n",
      "hint_text: Press the escape key to exit the opening animations\n",
      "puzzle_name: \n",
      "source: self\n",
      "{'source': './data/Thudbot_Hint_Data_1.csv', 'row': 0, 'question': 'How do I stop the opening movie', 'hint_level': '1', 'character': 'Player', 'speaker': '', 'narrative_context': 'Meta', 'planet': '', 'location': '', 'category': 'Meta', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': ''}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=f\"./data/Thudbot_Hint_Data_1.csv\",\n",
    "    metadata_columns=[\n",
    "        \"question\",\n",
    "        \"hint_level\",\n",
    "        \"character\",\n",
    "        \"speaker\",\n",
    "        \"narrative_context\",\n",
    "        \"planet\",\n",
    "        \"location\",\n",
    "        \"category\",\n",
    "        \"tone\",\n",
    "        \"follow_up_hint_id\",\n",
    "        \"answer_keywords\",\n",
    "        \"tags\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "hint_data = loader.load()\n",
    "\n",
    "# No need to overwrite page_content; not doing custom transformation\n",
    "print(hint_data[0].page_content)     # This will already be the hint_text\n",
    "print(hint_data[0].metadata)         # This will show all the metadata fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83858935",
   "metadata": {},
   "source": [
    "### Setting up QDrant! (from HW9)\n",
    "\n",
    "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"ThudbotHints\".\n",
    "\n",
    "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e047a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=hint_data,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Thudbot_Hints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42404f5",
   "metadata": {},
   "source": [
    "## Step 3: Synthetic data generation (SDG) with RAGAS to create a golden dataset\n",
    "\n",
    "Adapted from HW 7 & 9\n",
    "\n",
    "NOTE: this step is a one-time deal. Once the appropriate golden data set is finalized, don't run any of these cells, but pick up at the JSON import cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16656100",
   "metadata": {},
   "source": [
    "### ⏭️ Skip these steps until/unless want new golden data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156621a",
   "metadata": {},
   "source": [
    "#### Group data by narrative context\n",
    "\n",
    "the data is too granular for Ragas, I got this error:\n",
    "\n",
    "ValueError: Documents appears to be too short (ie 100 tokens or less). Please provide longer documents\n",
    "\n",
    "so,  I will to group it and \n",
    "Create a new list called  ```merged_docs``` , just to feed to ragas, but not for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9037046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from collections import defaultdict\n",
    "\n",
    "# Group hints by narrative context\n",
    "grouped = defaultdict(list)\n",
    "\n",
    "for doc in hint_data:\n",
    "    key = doc.metadata.get(\"narrative_context\", \"unknown\")\n",
    "    grouped[key].append(doc.page_content)\n",
    "\n",
    "# Create longer Documents for SDG\n",
    "merged_docs = [\n",
    "    Document(\n",
    "        page_content=\"\\n\".join(hints),\n",
    "        metadata={\"narrative_context\": context}\n",
    "    )\n",
    "    for context, hints in grouped.items()\n",
    "]\n",
    "\n",
    "# Optional: preview length\n",
    "for doc in merged_docs:\n",
    "    print(f\"{doc.metadata['narrative_context']}: {len(doc.page_content.split())} words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e012e8d",
   "metadata": {},
   "source": [
    "Need to select a random subset, because the data is grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284659a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "import random\n",
    "\n",
    "sampled_docs = random.sample(merged_docs, 5)\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "golden_dataset = generator.generate_with_langchain_docs(sampled_docs, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b52029",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4da258",
   "metadata": {},
   "source": [
    "save the RAGAS golden data set as a json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d636a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/goldendataset.json\", \"w\") as f:\n",
    "    json.dump([sample.model_dump() for sample in golden_dataset], f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f64552",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export Golden Dataset to Human-Readable Formats\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the golden dataset\n",
    "with open('./data/goldendataset.json', 'r') as f:\n",
    "    golden_data = json.load(f)\n",
    "\n",
    "# Extract the key information into a clean DataFrame\n",
    "readable_data = []\n",
    "for i, item in enumerate(golden_data):\n",
    "    eval_sample = item['eval_sample']\n",
    "    \n",
    "    # Clean up the reference contexts (truncate if too long)\n",
    "    contexts = eval_sample.get('reference_contexts', [])\n",
    "    contexts_preview = str(contexts[0])[:200] + \"...\" if contexts else \"No context\"\n",
    "    \n",
    "    readable_data.append({\n",
    "        'Question_ID': f\"Q{i+1:02d}\",\n",
    "        'User_Question': eval_sample.get('user_input', ''),\n",
    "        'Expected_Answer': eval_sample.get('reference', ''),\n",
    "        'Synthesizer_Type': item.get('synthesizer_name', ''),\n",
    "        'Context_Preview': contexts_preview,\n",
    "        'Full_Context_Length': len(str(contexts)) if contexts else 0\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(readable_data)\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv('./data/golden_dataset_readable.csv', index=False)\n",
    "\n",
    "# Display preview\n",
    "print(\"Golden Dataset Preview:\")\n",
    "print(\"=\" * 60)\n",
    "for _, row in df.head(3).iterrows():\n",
    "    print(f\"Question {row['Question_ID']}: {row['User_Question']}\")\n",
    "    print(f\"Expected: {row['Expected_Answer']}\")\n",
    "    print(f\"Synthesizer: {row['Synthesizer_Type']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(f\"\\n✅ Exported {len(df)} questions to: ./data/golden_dataset_readable.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9551336",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 2: Create Detailed Markdown Report\n",
    "\n",
    "def create_markdown_report(golden_data, output_file='./data/golden_dataset_report.md'):\n",
    "    \"\"\"Create a detailed, human-readable markdown report of the golden dataset.\"\"\"\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"# Thudbot Golden Dataset Report\\n\\n\")\n",
    "        f.write(\"Generated synthetic test questions and answers for RAGAS evaluation.\\n\\n\")\n",
    "        f.write(f\"**Total Questions:** {len(golden_data)}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        \n",
    "        for i, item in enumerate(golden_data, 1):\n",
    "            eval_sample = item['eval_sample']\n",
    "            \n",
    "            f.write(f\"## Question {i:02d}\\n\\n\")\n",
    "            f.write(f\"**User Input:** {eval_sample.get('user_input', 'N/A')}\\n\\n\")\n",
    "            f.write(f\"**Expected Answer:**\\n{eval_sample.get('reference', 'N/A')}\\n\\n\")\n",
    "            f.write(f\"**Synthesizer:** `{item.get('synthesizer_name', 'unknown')}`\\n\\n\")\n",
    "            \n",
    "            # Add context information\n",
    "            contexts = eval_sample.get('reference_contexts', [])\n",
    "            if contexts:\n",
    "                f.write(\"**Reference Context Preview:**\\n\")\n",
    "                context_preview = str(contexts[0])[:300] + \"...\" if len(str(contexts[0])) > 300 else str(contexts[0])\n",
    "                f.write(f\"```\\n{context_preview}\\n```\\n\\n\")\n",
    "            \n",
    "            f.write(\"---\\n\\n\")\n",
    "    \n",
    "    print(f\"✅ Created detailed report: {output_file}\")\n",
    "\n",
    "# Generate the markdown report\n",
    "create_markdown_report(golden_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e7aad",
   "metadata": {},
   "source": [
    "the answers are okay, but the questions are crappy. Let's see if we can get an LLM to rewrite the questions in a more natural game-player voice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0010f",
   "metadata": {},
   "source": [
    "##### Five step plan to re-write the questions:\n",
    "\n",
    "1. Define rewriter prompt\n",
    "2. Set up a rewriter chain using the rewriter prompt\n",
    "3. Define rewrite function that invokes rewriter_chain\n",
    "4. Run the function on the original \"golden\" dataset\n",
    "5. Write the re-written questions to platinum_dataset.json (and an .md file)\n",
    "\n",
    "\"Vibe-check\" the output, and iterate until I like it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee97c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question Rewriter: Transform Formal Questions → Casual Player Questions\n",
    "\n",
    "# Using the same pattern as HW7 for LLM chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the rewriter prompt (following HW7 prompt pattern)\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "QUESTION_REWRITER_PROMPT = \"\"\"\\\n",
    "You are helping rewrite questions to sound like real confused players asking for game hints.\n",
    "\n",
    "Your job is to transform formal/academic questions into casual, human-like questions that real players would ask when stuck in \"The Space Bar\" adventure game.\n",
    "\n",
    "IMPORTANT: If the question contains a question ID like \"TSB-041\" or similar, ignore that completely - it's just an organizational code that doesn't exist in the real game.\n",
    "\n",
    "Original question: {original_question}\n",
    "Game context: {context_preview}\n",
    "\n",
    "Examples of good player questions:\n",
    "- \"How do I get past the guard?\"\n",
    "- \"I'm stuck in this room, what do I do?\"\n",
    "- \"Help! I can't figure out this puzzle\"\n",
    "- \"Where's the token I need?\"\n",
    "\n",
    "Make it sound confused, or casual - like a real person, not an academic paper.\n",
    "\n",
    "Rewritten question:\"\"\"\n",
    "\n",
    "# Create the prompt template (same pattern as HW7)\n",
    "rewriter_prompt = ChatPromptTemplate.from_template(QUESTION_REWRITER_PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set up a rewriter chain using the rewriter prompt\n",
    "\n",
    "# Set up the LLM for rewriting (following HW7 pattern)\n",
    "rewriter_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# Create the rewriter chain (same LCEL pattern as HW7)\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "rewriter_chain = rewriter_prompt | rewriter_llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define rewrite function that invokes rewriter_chain\n",
    "# Main rewriting function (following HW7 iteration pattern)\n",
    "def rewrite_questions_to_player_style(golden_data):\n",
    "    \"\"\"Rewrite formal RAGAS questions to sound like casual game players\"\"\"\n",
    "    \n",
    "    updated_data = []\n",
    "    \n",
    "    print(\"🔄 Rewriting questions to sound like real players...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, item in enumerate(golden_data, 1):\n",
    "        eval_sample = item['eval_sample']\n",
    "        original_q = eval_sample.get('user_input', '')\n",
    "        \n",
    "        # Get context preview for better rewriting\n",
    "        contexts = eval_sample.get('reference_contexts', [])\n",
    "        context_preview = str(contexts[0])[:200] + \"...\" if contexts else \"No context available\"\n",
    "        \n",
    "        # Rewrite the question using our chain\n",
    "        try:\n",
    "            rewritten_q = rewriter_chain.invoke({\n",
    "                \"original_question\": original_q,\n",
    "                \"context_preview\": context_preview\n",
    "            })\n",
    "            \n",
    "            # Update the question in place\n",
    "            eval_sample['user_input'] = rewritten_q.strip()\n",
    "            eval_sample['original_question'] = original_q  # Keep original for comparison\n",
    "            \n",
    "            # Show progress\n",
    "            print(f\"✅ Question {i:02d}:\")\n",
    "            print(f\"   Original: {original_q[:70]}...\")\n",
    "            print(f\"   Rewritten: {rewritten_q.strip()[:70]}...\")\n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error rewriting question {i}: {e}\")\n",
    "            # Keep original if rewriting fails\n",
    "            eval_sample['original_question'] = original_q\n",
    "        \n",
    "        updated_data.append(item)\n",
    "    \n",
    "    print(f\"✅ Successfully rewrote {len(updated_data)} questions!\")\n",
    "    return updated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c249a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Run the re-writer on the original \"golden\" dataset\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the original golden dataset\n",
    "with open('./data/goldendataset.json', 'r') as f:\n",
    "    original_golden_data = json.load(f)\n",
    "\n",
    "print(f\"📊 Loaded {len(original_golden_data)} questions to rewrite\")\n",
    "\n",
    "# Rewrite the questions\n",
    "rewritten_data = rewrite_questions_to_player_style(original_golden_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31116011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Save the rewritten dataset and create comparison report\n",
    "with open('./data/platinum_dataset.json', 'w') as f:\n",
    "    json.dump(rewritten_data, f, indent=2)\n",
    "\n",
    "# Create a comparison report to review the changes\n",
    "def create_comparison_report(rewritten_data, output_file='./data/question_rewrite_comparison.md'):\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"# Question Rewriting Comparison Report\\n\\n\")\n",
    "        f.write(\"Comparison of original RAGAS questions vs. player-style questions\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        \n",
    "        for i, item in enumerate(rewritten_data, 1):\n",
    "            eval_sample = item['eval_sample']\n",
    "            original = eval_sample.get('original_question', 'N/A')\n",
    "            rewritten = eval_sample.get('user_input', 'N/A')\n",
    "            \n",
    "            f.write(f\"## Question {i:02d}\\n\\n\")\n",
    "            f.write(f\"**Original (RAGAS):** {original}\\n\\n\")\n",
    "            f.write(f\"**Rewritten (Player Style):** {rewritten}\\n\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    \n",
    "    print(f\"📝 Created comparison report: {output_file}\")\n",
    "\n",
    "create_comparison_report(rewritten_data)\n",
    "print(f\"💾 Saved rewritten dataset to: ./data/platinum_dataset.json\")\n",
    "print(\"\\n🎯 Ready to use the player-style questions for RAGAS evaluation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908666af",
   "metadata": {},
   "source": [
    "I ran a few iterations with different prompts, and an now reasonably happy with the questions. \n",
    "\n",
    "Next step is to import the ```platinum_dataset.json``` for use by ragas eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cacdfd8",
   "metadata": {},
   "source": [
    "#### End of SDG work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36831f3",
   "metadata": {},
   "source": [
    "### ▶️ Resume here to load data for any RAGAS eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15427af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load questions for testing retrievers\n",
    "with open(\"data/platinum_dataset.json\", \"r\") as f:\n",
    "    platinum_data = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017455bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cb2736",
   "metadata": {},
   "source": [
    "## Step 4: Setup the RAG chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc850ac",
   "metadata": {},
   "source": [
    "Starting with a \"naive\" dense vector retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1274cae5",
   "metadata": {},
   "source": [
    "### R - Retrieval\n",
    "\n",
    "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
    "\n",
    "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a67ec143",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d781088a",
   "metadata": {},
   "source": [
    "### A - Augmented\n",
    "\n",
    "My first pass at a Thud-like prompt, named as ```THUD_TEMPLATE```\n",
    "\n",
    "This will need tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a920e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "THUD_TEMPLATE = \"\"\"\\\n",
    "You are Thud, a friendly and somewhat simple-minded patron at The Thirsty Tentacle. \n",
    "\n",
    "You're trying your best to help the player navigate the game \"The Space Bar.\"\n",
    "\n",
    "Use the clues and context provided below to offer a gentle hint — not a full solution.\n",
    "\n",
    "If you're not sure, say so, or suggest the player look around more.\n",
    "\n",
    "Player's question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Your hint:\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(THUD_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e84599",
   "metadata": {},
   "source": [
    "### G - Generation\n",
    "\n",
    "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d27603ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "#chat_model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43372065",
   "metadata": {},
   "source": [
    "### LCEL RAG Chain\n",
    "\n",
    "We're going to use LCEL to construct our chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e85297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "naive_retrieval_chain = (\n",
    "    \n",
    "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
    "    \n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc3681",
   "metadata": {},
   "source": [
    "Test the chain, and the langsmith tracing with a question.\n",
    "Might as well take the question from the platinum data set (just remember to load it above ▶️)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b91e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': AIMessage(content=\"Well, Yzore's a tricky place, but I think the Yzore helps you because you need a special token to hop on a bus there. Maybe there's something at Glom Hole or around that mailbox that can help you get it. Keep looking around in those spots—you might find a clue or item that'll get you closer to your goal!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 2067, 'total_tokens': 2138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-C0FBkhEpUPOjVrDBoI6Q5mzP4sJbT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0cbf6144-0850-4f7c-818a-32c915fc6738-0', usage_metadata={'input_tokens': 2067, 'output_tokens': 71, 'total_tokens': 2138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " 'context': [Document(metadata={'source': './data/Thudbot_Hint_Data_1.csv', 'row': 78, 'question': 'How do I get on the bus to Quantelope Lodge?', 'hint_level': '1', 'character': 'Fleebix, Thud', 'speaker': '', 'narrative_context': 'Fleebix Flashback', 'planet': 'Yzore', 'location': 'Front Stoop', 'category': 'Puzzle', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': '', '_id': 'd968e09b6ae5446bb648231242a38acc', '_collection_name': 'Thudbot_Hints'}, page_content='question_id: TSB-046\\nhint_text: You need a token to get on a bus in Yzore\\npuzzle_name: Getting to Quantelope Lodge\\nsource: UHS'),\n",
       "  Document(metadata={'source': './data/Thudbot_Hint_Data_1.csv', 'row': 86, 'question': 'Thud got on the wrong bus.', 'hint_level': '2', 'character': 'Fleebix, Thud', 'speaker': '', 'narrative_context': 'Fleebix Flashback', 'planet': 'Yzore', 'location': 'Glom Hole', 'category': 'Puzzle', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': '', '_id': '8edb39d061194a56a3ed96d9c2c29d90', '_collection_name': 'Thudbot_Hints'}, page_content=\"question_id: TSB-048\\nhint_text: Maybe there's something you can do at Glom Hole?\\npuzzle_name: Getting to Quantelope Lodge\\nsource: UHS\"),\n",
       "  Document(metadata={'source': './data/Thudbot_Hint_Data_1.csv', 'row': 76, 'question': 'How do I get to the Quantelope lodge', 'hint_level': '1', 'character': 'Fleebix, Thud', 'speaker': '', 'narrative_context': 'Fleebix Flashback', 'planet': 'Yzore', 'location': 'Front Stoop', 'category': 'Puzzle', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': '', '_id': 'e4e99c1fe7ec46ae9abf99bea4ff7768', '_collection_name': 'Thudbot_Hints'}, page_content='question_id: TSB-045\\nhint_text: To get to the Quantelpoe Lodge, Thud and Fleebix should take a bus\\npuzzle_name: Getting to Quantelope Lodge\\nsource: UHS'),\n",
       "  Document(metadata={'source': './data/Thudbot_Hint_Data_1.csv', 'row': 70, 'question': 'How do I find Thud when I am in a jar?', 'hint_level': '1', 'character': 'Fleebix', 'speaker': '', 'narrative_context': 'Fleebix Flashback', 'planet': 'Yzore', 'location': 'Front Stoop', 'category': 'Puzzle', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': '', '_id': '5ae286f1d89d4256ad8169c3faf34c9f', '_collection_name': 'Thudbot_Hints'}, page_content=\"question_id: TSB-042\\nhint_text: I could tell you how to find Thud, but maybe you should EmpTel with Thud first if you haven't\\npuzzle_name: Getting to Quantelope Lodge\\nsource: UHS\"),\n",
       "  Document(metadata={'source': './data/Thudbot_Hint_Data_1.csv', 'row': 74, 'question': 'What do I need to do in the Fleebix  flashback?', 'hint_level': '2', 'character': 'Fleebix', 'speaker': '', 'narrative_context': 'Fleebix Flashback', 'planet': 'Yzore', 'location': '', 'category': 'Puzzle', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': '', '_id': '057ea13907b449de823c8c8a30be8145', '_collection_name': 'Thudbot_Hints'}, page_content='question_id: TSB-044\\nhint_text: Read the audition notice to find out where Thud and Fleebix need to go first\\npuzzle_name: Getting to Quantelope Lodge\\nsource: UHS'),\n",
       "  Document(metadata={'source': './data/Thudbot_Hint_Data_1.csv', 'row': 75, 'question': 'What do I need to do in the Fleebix  flashback?', 'hint_level': '3', 'character': 'Fleebix', 'speaker': '', 'narrative_context': 'Fleebix Flashback', 'planet': 'Yzore', 'location': '', 'category': 'Puzzle', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': '', '_id': 'bd32f769dddd4552a4caa936eef7b286', '_collection_name': 'Thudbot_Hints'}, page_content='question_id: TSB-044\\nhint_text: Thud and Fleebix need to get to the Quantelope Lodge\\npuzzle_name: Getting to Quantelope Lodge\\nsource: UHS'),\n",
       "  Document(metadata={'source': './data/Thudbot_Hint_Data_1.csv', 'row': 102, 'question': 'What can I do inside the mail truck?', 'hint_level': '1', 'character': 'Fleebix, Thud', 'speaker': '', 'narrative_context': 'Fleebix Flashback', 'planet': 'Yzore', 'location': 'Mail truck', 'category': 'Puzzle', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': '', '_id': 'd4cd51f7c55e4cb2a0ace6df3947dbdc', '_collection_name': 'Thudbot_Hints'}, page_content=\"question_id: TSB-054\\nhint_text: Not much to do here. Look around the truck. Don't get caught.\\npuzzle_name: Getting to Quantelope Lodge\\nsource: UHS\"),\n",
       "  Document(metadata={'source': './data/Thudbot_Hint_Data_1.csv', 'row': 88, 'question': 'How do I get to Quantelope Lodge from Glom Hole', 'hint_level': '2', 'character': 'Fleebix, Thud', 'speaker': '', 'narrative_context': 'Fleebix Flashback', 'planet': 'Yzore', 'location': 'Glom Hole', 'category': 'Puzzle', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': '', '_id': '8b877f074dfe43df887db20970a355b2', '_collection_name': 'Thudbot_Hints'}, page_content='question_id: TSB-049\\nhint_text: Have you looked at the mailbox near Glom Hole?\\npuzzle_name: Getting to Quantelope Lodge\\nsource: UHS'),\n",
       "  Document(metadata={'source': './data/Thudbot_Hint_Data_1.csv', 'row': 69, 'question': \"Why can't I do anything when I EmpTel as Fleebix\", 'hint_level': '2', 'character': 'Fleebix', 'speaker': '', 'narrative_context': 'Fleebix Flashback', 'planet': 'Yzore', 'location': '', 'category': 'Puzzle', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': '', '_id': 'e7adb477f8c14466b25320ee4f3159be', '_collection_name': 'Thudbot_Hints'}, page_content='question_id: TSB-041\\nhint_text: When you are Fleebix, you can rely on Thud to help you with many taks\\npuzzle_name: Getting to Quantelope Lodge\\nsource: UHS'),\n",
       "  Document(metadata={'source': './data/Thudbot_Hint_Data_1.csv', 'row': 106, 'question': 'What can I do inside the mail truck?', 'hint_level': '4', 'character': 'Fleebix, Thud', 'speaker': '', 'narrative_context': 'Fleebix Flashback', 'planet': 'Yzore', 'location': 'Cardboard Box', 'category': 'Puzzle', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': '', '_id': 'af04010d0cac453792fb997aad11a03a', '_collection_name': 'Thudbot_Hints'}, page_content='question_id: TSB-054\\nhint_text: Wait for the truck to deliver you\\npuzzle_name: Getting to Quantelope Lodge\\nsource: UHS')]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_q = platinum_data[0][\"eval_sample\"][\"user_input\"]\n",
    "naive_retrieval_chain.invoke({\"question\": sample_q})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb0b03",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate results with RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to run selected retriever on the eval (platinum) data\n",
    "# import time\n",
    "\n",
    "def run_retriever_on_dataset(name, retriever_chain, platinum_data):\n",
    "    \"\"\"Run retriever and format for Ragas evaluation - using the platinum dataset\"\"\"\n",
    "    print(f\"Running {name} on platinum data\")\n",
    "    outputs = []\n",
    "    \n",
    "    for item in platinum_data:\n",
    "        question = item[\"eval_sample\"][\"user_input\"]\n",
    "        reference = item[\"eval_sample\"][\"reference\"]\n",
    "        \n",
    "        # Run retriever\n",
    "        response = retriever_chain.invoke({\"question\": question})\n",
    "        \n",
    "        outputs.append({\n",
    "            \"user_input\": question,\n",
    "            \"reference\": reference,\n",
    "            \"response\": response[\"response\"].content if hasattr(response[\"response\"], \"content\") else response[\"response\"],\n",
    "            \"retrieved_contexts\": [ctx.page_content for ctx in response[\"context\"]],\n",
    "            \"retriever_name\": name\n",
    "        })\n",
    "\n",
    "    #    # Add delay between requests if needed (for rate limiting)\n",
    "    #     if i < len(platinum_dataset) - 1:  # Don't sleep after last item\n",
    "    #         print(f\"  Waiting 2 seconds before next request...\")\n",
    "    #         time.sleep(2)  # Adjust this value as needed\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd769b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running naive on platinum dataset\n"
     ]
    }
   ],
   "source": [
    "naive_outputs = run_retriever_on_dataset(\"naive\", naive_retrieval_chain, platinum_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_outputs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b7567",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_outputs = run_retriever_on_dataset(\"naive\", naive_retrieval_chain, platinum_data)\n",
    "# bm25_outputs = run_retriever_on_dataset(\"bm25\", bm25_retrieval_chain, platinum_data)\n",
    "# multi_query_outputs = run_retriever_on_dataset(\"multi_query\", multi_query_retrieval_chain, platinum_data)\n",
    "# parent_doc_outputs = run_retriever_on_dataset(\"parent_doc\", parent_document_retrieval_chain, platinum_data)\n",
    "# ensemble_outputs = run_retriever_on_dataset(\"ensemble\", ensemble_retrieval_chain, platinum_data)\n",
    "# contextual_compression_outputs = run_retriever_on_dataset(\"contextual_compression\", contextual_compression_retrieval_chain, platinum_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63669ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ragas import EvaluationDataset\n",
    "\n",
    "# Step 1: Convert to DataFrame\n",
    "naive_df = pd.DataFrame(naive_outputs)\n",
    "# bm25_df = pd.DataFrame(bm25_outputs)\n",
    "# multi_query_df = pd.DataFrame(multi_query_outputs)\n",
    "# parent_doc_df = pd.DataFrame(parent_doc_outputs)\n",
    "# ensemble_df = pd.DataFrame(ensemble_outputs)\n",
    "# contextual_compression_df = pd.DataFrame(contextual_compression_outputs)\n",
    "\n",
    "# Step 2: Convert to Ragas-compatible EvaluationDataset\n",
    "naive_eval_dataset = EvaluationDataset.from_pandas(naive_df)\n",
    "# bm25_eval_dataset = EvaluationDataset.from_pandas(bm25_df)\n",
    "# multi_query_eval_dataset = EvaluationDataset.from_pandas(multi_query_df)\n",
    "# parent_doc_eval_dataset = EvaluationDataset.from_pandas(parent_doc_df)\n",
    "# ensemble_eval_dataset = EvaluationDataset.from_pandas(ensemble_df)\n",
    "# contextual_compression_eval_dataset = EvaluationDataset.from_pandas(contextual_compression_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59a3ac64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference</th>\n",
       "      <th>response</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>retriever_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Wait, what’s the deal with the Yzore? How doe...</td>\n",
       "      <td>The hint_text indicates that in Yzore, you nee...</td>\n",
       "      <td>Oh, Yzore is the planet where all the bus acti...</td>\n",
       "      <td>[question_id: TSB-046\\nhint_text: You need a t...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Uh, I'm kinda lost here. What am I supposed t...</td>\n",
       "      <td>You can't do much on your own as Fleebix, beca...</td>\n",
       "      <td>Oh, hey there! As Fleebix inside the jar, you ...</td>\n",
       "      <td>[question_id: TSB-041\\nhint_text: You can't do...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Wait, what does UHS even mean in this game?\"</td>\n",
       "      <td>UHS is referenced as the source for puzzles an...</td>\n",
       "      <td>Oh, UHS, huh? Well, it sounds like it's someth...</td>\n",
       "      <td>[question_id: TSB-069\\nhint_text: To omplete t...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Wait, what am I supposed to do in this entry ...</td>\n",
       "      <td>Thud is not very bright.</td>\n",
       "      <td>Oh, hi there! In the entry vestibule, it might...</td>\n",
       "      <td>[question_id: TSB-019\\nhint_text: Look around ...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Hey, I'm really stuck! How do I use the resid...</td>\n",
       "      <td>The residue printer can tell you who may have ...</td>\n",
       "      <td>Hey there, friend! From what I remember, the r...</td>\n",
       "      <td>[question_id: TSB-039\\nhint_text: You better c...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Hey, how do I use these tokens for the bus? A...</td>\n",
       "      <td>In the context, you need a token to get on the...</td>\n",
       "      <td>Hey there! Seems like you're lookin' for a way...</td>\n",
       "      <td>[question_id: TSB-046\\nhint_text: You need a t...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Okay, so I'm trying to get to the Quantelope ...</td>\n",
       "      <td>To effectively navigate the Simulator and expl...</td>\n",
       "      <td>Oh hey there! Looks like getting to the Quante...</td>\n",
       "      <td>[question_id: TSB-045\\nhint_text: To get to th...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Wait, how am I supposed to get to Quantelope ...</td>\n",
       "      <td>Fleebix can't do much alone and needs Thud's h...</td>\n",
       "      <td>Oh hey there! Well, to get to Quantelope Lodge...</td>\n",
       "      <td>[question_id: TSB-042\\nhint_text: I could tell...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Wait, how do I get to Quantelope Lodge with T...</td>\n",
       "      <td>First, you need to find Thud and Fleebix and g...</td>\n",
       "      <td>Oh, hey there! It sounds like you're tryin' to...</td>\n",
       "      <td>[question_id: TSB-045\\nhint_text: To get to th...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Wait, how do Fleebix and Thud even get to the...</td>\n",
       "      <td>Fleebix and Thud need to reach the Quantelope ...</td>\n",
       "      <td>Oh, heh, so you're wonderin' how Fleebix and T...</td>\n",
       "      <td>[question_id: TSB-041\\nhint_text: When you are...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Hey, I'm totally lost! I keep hearing about t...</td>\n",
       "      <td>To effectively progress in the game, a casual ...</td>\n",
       "      <td>Hey there, friend! If you're lookin' for Thud,...</td>\n",
       "      <td>[question_id: TSB-042\\nhint_text: I could tell...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Wait, how do the hints about fixing the termi...</td>\n",
       "      <td>The TSB-031 hints indicate that the terminal i...</td>\n",
       "      <td>Oh, I see you're a bit confused! Well, the clu...</td>\n",
       "      <td>[question_id: TSB-042\\nhint_text: I could tell...</td>\n",
       "      <td>naive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   \"Wait, what’s the deal with the Yzore? How doe...   \n",
       "1   \"Uh, I'm kinda lost here. What am I supposed t...   \n",
       "2       \"Wait, what does UHS even mean in this game?\"   \n",
       "3   \"Wait, what am I supposed to do in this entry ...   \n",
       "4   \"Hey, I'm really stuck! How do I use the resid...   \n",
       "5   \"Hey, how do I use these tokens for the bus? A...   \n",
       "6   \"Okay, so I'm trying to get to the Quantelope ...   \n",
       "7   \"Wait, how am I supposed to get to Quantelope ...   \n",
       "8   \"Wait, how do I get to Quantelope Lodge with T...   \n",
       "9   \"Wait, how do Fleebix and Thud even get to the...   \n",
       "10  \"Hey, I'm totally lost! I keep hearing about t...   \n",
       "11  \"Wait, how do the hints about fixing the termi...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The hint_text indicates that in Yzore, you nee...   \n",
       "1   You can't do much on your own as Fleebix, beca...   \n",
       "2   UHS is referenced as the source for puzzles an...   \n",
       "3                            Thud is not very bright.   \n",
       "4   The residue printer can tell you who may have ...   \n",
       "5   In the context, you need a token to get on the...   \n",
       "6   To effectively navigate the Simulator and expl...   \n",
       "7   Fleebix can't do much alone and needs Thud's h...   \n",
       "8   First, you need to find Thud and Fleebix and g...   \n",
       "9   Fleebix and Thud need to reach the Quantelope ...   \n",
       "10  To effectively progress in the game, a casual ...   \n",
       "11  The TSB-031 hints indicate that the terminal i...   \n",
       "\n",
       "                                             response  \\\n",
       "0   Oh, Yzore is the planet where all the bus acti...   \n",
       "1   Oh, hey there! As Fleebix inside the jar, you ...   \n",
       "2   Oh, UHS, huh? Well, it sounds like it's someth...   \n",
       "3   Oh, hi there! In the entry vestibule, it might...   \n",
       "4   Hey there, friend! From what I remember, the r...   \n",
       "5   Hey there! Seems like you're lookin' for a way...   \n",
       "6   Oh hey there! Looks like getting to the Quante...   \n",
       "7   Oh hey there! Well, to get to Quantelope Lodge...   \n",
       "8   Oh, hey there! It sounds like you're tryin' to...   \n",
       "9   Oh, heh, so you're wonderin' how Fleebix and T...   \n",
       "10  Hey there, friend! If you're lookin' for Thud,...   \n",
       "11  Oh, I see you're a bit confused! Well, the clu...   \n",
       "\n",
       "                                   retrieved_contexts retriever_name  \n",
       "0   [question_id: TSB-046\\nhint_text: You need a t...          naive  \n",
       "1   [question_id: TSB-041\\nhint_text: You can't do...          naive  \n",
       "2   [question_id: TSB-069\\nhint_text: To omplete t...          naive  \n",
       "3   [question_id: TSB-019\\nhint_text: Look around ...          naive  \n",
       "4   [question_id: TSB-039\\nhint_text: You better c...          naive  \n",
       "5   [question_id: TSB-046\\nhint_text: You need a t...          naive  \n",
       "6   [question_id: TSB-045\\nhint_text: To get to th...          naive  \n",
       "7   [question_id: TSB-042\\nhint_text: I could tell...          naive  \n",
       "8   [question_id: TSB-045\\nhint_text: To get to th...          naive  \n",
       "9   [question_id: TSB-041\\nhint_text: When you are...          naive  \n",
       "10  [question_id: TSB-042\\nhint_text: I could tell...          naive  \n",
       "11  [question_id: TSB-042\\nhint_text: I could tell...          naive  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_df\n",
    "# bm25_df\n",
    "# multi_query_df\n",
    "# parent_doc_df\n",
    "# ensemble_df\n",
    "# contextual_compression_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
