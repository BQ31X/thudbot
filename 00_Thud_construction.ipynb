{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc5f067",
   "metadata": {},
   "source": [
    "# Scaffold\n",
    "Prototype Thudbot in jupyter, then figure out how to convert to a .py   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad5c4c3",
   "metadata": {},
   "source": [
    "\n",
    "Naming this 00_ so that it will be the first notebook every time I start a new session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9badc3b1",
   "metadata": {},
   "source": [
    "#### Step 1 Source all the keys and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182642a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- API Key Status ---\n",
      "OPENAI_API_KEY loaded: True\n",
      "LANGCHAIN_API_KEY loaded: True\n",
      "TAVILY_API_KEY loaded: True\n",
      "RAGAS_API_KEY loaded: False\n",
      "ANTHROPIC_API_KEY loaded: True\n",
      "COHERE_API_KEY loaded: True\n",
      "\n",
      "--- Project Settings Status ---\n",
      "DEBUG mode enabled: True\n",
      "LangSmith Tracing V2 enabled: True\n",
      "LangChain Project Base: THUDBOT-CC\n"
     ]
    }
   ],
   "source": [
    "### API key management\n",
    "\n",
    "### Reminder: Place .env file inside the root of the project folder so when calling the below from inside the notebook it should find the .env fule and load it inside the notebook environment\n",
    "### PLEASE ADD THIS `.env` FILE TO YOUR PROJECT'S `.gitignore` file before committing and pushing the changes to your remote repo, as it contains API Keys and Secrets in it\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "# --- Verify API Keys ---\n",
    "print(\"--- API Key Status ---\")\n",
    "print(f\"OPENAI_API_KEY loaded: {'OPENAI_API_KEY' in os.environ}\")\n",
    "print(f\"LANGCHAIN_API_KEY loaded: {'LANGCHAIN_API_KEY' in os.environ}\")\n",
    "print(f\"TAVILY_API_KEY loaded: {'TAVILY_API_KEY' in os.environ}\")\n",
    "print(f\"RAGAS_API_KEY loaded: {'RAGAS_API_KEY' in os.environ}\")\n",
    "print(f\"ANTHROPIC_API_KEY loaded: {'ANTHROPIC_API_KEY' in os.environ}\")\n",
    "print(f\"COHERE_API_KEY loaded: {'COHERE_API_KEY' in os.environ}\")\n",
    "\n",
    "# --- Verify General Settings ---\n",
    "print(\"\\n--- Project Settings Status ---\")\n",
    "print(f\"DEBUG mode enabled: {os.environ.get('DEBUG') == 'True'}\")\n",
    "print(f\"LangSmith Tracing V2 enabled: {os.environ.get('LANGCHAIN_TRACING_V2') == 'true'}\")\n",
    "print(f\"LangChain Project Base: {os.environ.get('LANGCHAIN_PROJECT_BASE')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09fc64",
   "metadata": {},
   "source": [
    "including nltk, because it worked before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "140254c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/family/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/family/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854ab91",
   "metadata": {},
   "source": [
    "## Step 2: Data Collection and Preparation\n",
    "\n",
    "My data is CSV structured, so using code from HW9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89bf5b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_id: TSB-001\n",
      "hint_text: Press the escape key to exit the opening animations\n",
      "puzzle_name: \n",
      "source: self\n",
      "{'source': './data/Thudbot_Hint_Data_1.csv', 'row': 0, 'question': 'How do I stop the opening movie', 'hint_level': '1', 'character': 'Player', 'speaker': '', 'narrative_context': 'Meta', 'planet': '', 'location': '', 'category': 'Meta', 'tone': '', 'follow_up_hint_id': '', 'answer_keywords': '', 'tags': ''}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=f\"./data/Thudbot_Hint_Data_1.csv\",\n",
    "    metadata_columns=[\n",
    "        \"question\",\n",
    "        \"hint_level\",\n",
    "        \"character\",\n",
    "        \"speaker\",\n",
    "        \"narrative_context\",\n",
    "        \"planet\",\n",
    "        \"location\",\n",
    "        \"category\",\n",
    "        \"tone\",\n",
    "        \"follow_up_hint_id\",\n",
    "        \"answer_keywords\",\n",
    "        \"tags\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "hint_data = loader.load()\n",
    "\n",
    "# No need to overwrite page_content; not doing custom transformation\n",
    "print(hint_data[0].page_content)     # This will already be the hint_text\n",
    "print(hint_data[0].metadata)         # This will show all the metadata fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83858935",
   "metadata": {},
   "source": [
    "## Step 3: Setting up QDrant! (from HW9)\n",
    "\n",
    "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"ThudbotHints\".\n",
    "\n",
    "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55e047a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=hint_data,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Thudbot_Hints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42404f5",
   "metadata": {},
   "source": [
    "#### Step 3: Golden Data Set SDG from RAGAS\n",
    "\n",
    "Adapted from HW 7 & 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06eb6339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/family/Library/Mobile Documents/com~apple~CloudDocs/AppDev/thudbot/.venv/lib/python3.13/site-packages/pysbd/segmenter.py:66: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  for match in re.finditer('{0}\\s*'.format(re.escape(sent)), self.original_text):\n",
      "/Users/family/Library/Mobile Documents/com~apple~CloudDocs/AppDev/thudbot/.venv/lib/python3.13/site-packages/pysbd/lang/arabic.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  txt = re.sub('(?<={0})\\.'.format(am), '∯', txt)\n",
      "/Users/family/Library/Mobile Documents/com~apple~CloudDocs/AppDev/thudbot/.venv/lib/python3.13/site-packages/pysbd/lang/persian.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  txt = re.sub('(?<={0})\\.'.format(am), '∯', txt)\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156621a",
   "metadata": {},
   "source": [
    "#### Group data by narrative context\n",
    "\n",
    "the data is too granular for Ragas, I got this error:\n",
    "\n",
    "ValueError: Documents appears to be too short (ie 100 tokens or less). Please provide longer documents\n",
    "\n",
    "so,  I will to group it and \n",
    "Create a new list called  ```merged_docs``` , just to feed to ragas, but not for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9037046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta: 505 words\n",
      "Bar: 562 words\n",
      "Background: 75 words\n",
      "Thud Flashback: 94 words\n",
      "Fleebix Flashback: 1725 words\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from collections import defaultdict\n",
    "\n",
    "# Group hints by narrative context\n",
    "grouped = defaultdict(list)\n",
    "\n",
    "for doc in hint_data:\n",
    "    key = doc.metadata.get(\"narrative_context\", \"unknown\")\n",
    "    grouped[key].append(doc.page_content)\n",
    "\n",
    "# Create longer Documents for SDG\n",
    "merged_docs = [\n",
    "    Document(\n",
    "        page_content=\"\\n\".join(hints),\n",
    "        metadata={\"narrative_context\": context}\n",
    "    )\n",
    "    for context, hints in grouped.items()\n",
    "]\n",
    "\n",
    "# Optional: preview length\n",
    "for doc in merged_docs:\n",
    "    print(f\"{doc.metadata['narrative_context']}: {len(doc.page_content.split())} words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e012e8d",
   "metadata": {},
   "source": [
    "Need to select a random subset, because the data is grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "284659a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c9e99a0fc746f5b5a28de83834827b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6521b440694aa184d90f806e62c3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.testset.transforms.engine:unable to apply transformation: 'headlines' property not found in this node\n",
      "ERROR:ragas.testset.transforms.engine:unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7edd723de824d49943c6a65dfa87329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ragas.testset.transforms.base:Property 'summary' already exists in node '6d851d'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1076117c51ce4974bdda35295c134e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48518af989c492d96bed62f313d8596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ragas.testset.transforms.base:Property 'summary_embedding' already exists in node '6d851d'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da26a481ffb4335a62b31f31a2654fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66616d685ac49fa8224615bea72cbf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9efaad988d44db8d02c87a9b6ba0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d365cb58f74412090ff17a14b9f8bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "import random\n",
    "\n",
    "sampled_docs = random.sample(merged_docs, 5)\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "golden_dataset = generator.generate_with_langchain_docs(sampled_docs, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40b52029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the context of the game, what is the signif...</td>\n",
       "      <td>[question_id: TSB-045 hint_text: To get to the...</td>\n",
       "      <td>The hint_text indicates that in Yzore, you nee...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSB-041 what do I do?</td>\n",
       "      <td>[question_id: TSB-041 hint_text: You can't do ...</td>\n",
       "      <td>You can't do much on your own as Fleebix, beca...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What UHS mean in the game?</td>\n",
       "      <td>[look in the small package when you were insid...</td>\n",
       "      <td>UHS is referenced as the source for puzzles an...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WhaT is TSB-027?</td>\n",
       "      <td>[question_id: TSB-019 hint_text: Look around i...</td>\n",
       "      <td>Thud is not very bright.</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H0w do the residue printer and fingerprint ana...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nquestion_id: TSB-019 hint_text: Lo...</td>\n",
       "      <td>The residue printer can tell you who may have ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>how use tokens for bus and find object like do...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nquestion_id: TSB-045 hint_text: To...</td>\n",
       "      <td>In the context, you need a token to get on the...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can you effectively utilize navigation and...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nquestion_id: TSB-045 hint_text: To...</td>\n",
       "      <td>To effectively navigate the Simulator and expl...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How Fleebix rely on Thud and follow clues to g...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nquestion_id: TSB-041 hint_text: Yo...</td>\n",
       "      <td>Fleebix can't do much alone and needs Thud's h...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>how to get to Quantelope Lodge with Thud and F...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nquestion_id: TSB-041 hint_text: Yo...</td>\n",
       "      <td>First, you need to find Thud and Fleebix and g...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do Fleebix and Thud get to the Quantelope ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nquestion_id: TSB-041 hint_text: Yo...</td>\n",
       "      <td>Fleebix and Thud need to reach the Quantelope ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How can a casual adventure gamer utilize the c...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nquestion_id: TSB-019 hint_text: Lo...</td>\n",
       "      <td>To effectively progress in the game, a casual ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How do the TSB-031 hints about fixing or tryin...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nquestion_id: TSB-019 hint_text: Lo...</td>\n",
       "      <td>The TSB-031 hints indicate that the terminal i...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   In the context of the game, what is the signif...   \n",
       "1                               TSB-041 what do I do?   \n",
       "2                          What UHS mean in the game?   \n",
       "3                                    WhaT is TSB-027?   \n",
       "4   H0w do the residue printer and fingerprint ana...   \n",
       "5   how use tokens for bus and find object like do...   \n",
       "6   How can you effectively utilize navigation and...   \n",
       "7   How Fleebix rely on Thud and follow clues to g...   \n",
       "8   how to get to Quantelope Lodge with Thud and F...   \n",
       "9   How do Fleebix and Thud get to the Quantelope ...   \n",
       "10  How can a casual adventure gamer utilize the c...   \n",
       "11  How do the TSB-031 hints about fixing or tryin...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [question_id: TSB-045 hint_text: To get to the...   \n",
       "1   [question_id: TSB-041 hint_text: You can't do ...   \n",
       "2   [look in the small package when you were insid...   \n",
       "3   [question_id: TSB-019 hint_text: Look around i...   \n",
       "4   [<1-hop>\\n\\nquestion_id: TSB-019 hint_text: Lo...   \n",
       "5   [<1-hop>\\n\\nquestion_id: TSB-045 hint_text: To...   \n",
       "6   [<1-hop>\\n\\nquestion_id: TSB-045 hint_text: To...   \n",
       "7   [<1-hop>\\n\\nquestion_id: TSB-041 hint_text: Yo...   \n",
       "8   [<1-hop>\\n\\nquestion_id: TSB-041 hint_text: Yo...   \n",
       "9   [<1-hop>\\n\\nquestion_id: TSB-041 hint_text: Yo...   \n",
       "10  [<1-hop>\\n\\nquestion_id: TSB-019 hint_text: Lo...   \n",
       "11  [<1-hop>\\n\\nquestion_id: TSB-019 hint_text: Lo...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The hint_text indicates that in Yzore, you nee...   \n",
       "1   You can't do much on your own as Fleebix, beca...   \n",
       "2   UHS is referenced as the source for puzzles an...   \n",
       "3                            Thud is not very bright.   \n",
       "4   The residue printer can tell you who may have ...   \n",
       "5   In the context, you need a token to get on the...   \n",
       "6   To effectively navigate the Simulator and expl...   \n",
       "7   Fleebix can't do much alone and needs Thud's h...   \n",
       "8   First, you need to find Thud and Fleebix and g...   \n",
       "9   Fleebix and Thud need to reach the Quantelope ...   \n",
       "10  To effectively progress in the game, a casual ...   \n",
       "11  The TSB-031 hints indicate that the terminal i...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4da258",
   "metadata": {},
   "source": [
    "saving the RAGAS golden data set for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d636a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/goldendataset.json\", \"w\") as f:\n",
    "    json.dump([sample.model_dump() for sample in golden_dataset], f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65f64552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden Dataset Preview:\n",
      "============================================================\n",
      "Question Q01: In the context of the game, what is the significance of the Yzore in reaching the Quantelope Lodge?\n",
      "Expected: The hint_text indicates that in Yzore, you need a token to get on a bus, and there's a token in the cup. You can ask Thud to take the token from the cup, which is part of the process to reach the Quantelope Lodge.\n",
      "Synthesizer: single_hop_specifc_query_synthesizer\n",
      "----------------------------------------\n",
      "Question Q02: TSB-041 what do I do?\n",
      "Expected: You can't do much on your own as Fleebix, because you are in a jar. To progress, you might need to rely on Thud to help you with many tasks, such as finding Thud or interacting with objects like the door or the cup, to get to Quantelope Lodge.\n",
      "Synthesizer: single_hop_specifc_query_synthesizer\n",
      "----------------------------------------\n",
      "Question Q03: What UHS mean in the game?\n",
      "Expected: UHS is referenced as the source for puzzles and hints in the game, such as Clocktower and Navigation Simulator, but the specific meaning of UHS is not provided in the context.\n",
      "Synthesizer: single_hop_specifc_query_synthesizer\n",
      "----------------------------------------\n",
      "\n",
      "✅ Exported 12 questions to: ./data/golden_dataset_readable.csv\n"
     ]
    }
   ],
   "source": [
    "## Export Golden Dataset to Human-Readable Formats\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the golden dataset\n",
    "with open('./data/goldendataset.json', 'r') as f:\n",
    "    golden_data = json.load(f)\n",
    "\n",
    "# Extract the key information into a clean DataFrame\n",
    "readable_data = []\n",
    "for i, item in enumerate(golden_data):\n",
    "    eval_sample = item['eval_sample']\n",
    "    \n",
    "    # Clean up the reference contexts (truncate if too long)\n",
    "    contexts = eval_sample.get('reference_contexts', [])\n",
    "    contexts_preview = str(contexts[0])[:200] + \"...\" if contexts else \"No context\"\n",
    "    \n",
    "    readable_data.append({\n",
    "        'Question_ID': f\"Q{i+1:02d}\",\n",
    "        'User_Question': eval_sample.get('user_input', ''),\n",
    "        'Expected_Answer': eval_sample.get('reference', ''),\n",
    "        'Synthesizer_Type': item.get('synthesizer_name', ''),\n",
    "        'Context_Preview': contexts_preview,\n",
    "        'Full_Context_Length': len(str(contexts)) if contexts else 0\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(readable_data)\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv('./data/golden_dataset_readable.csv', index=False)\n",
    "\n",
    "# Display preview\n",
    "print(\"Golden Dataset Preview:\")\n",
    "print(\"=\" * 60)\n",
    "for _, row in df.head(3).iterrows():\n",
    "    print(f\"Question {row['Question_ID']}: {row['User_Question']}\")\n",
    "    print(f\"Expected: {row['Expected_Answer']}\")\n",
    "    print(f\"Synthesizer: {row['Synthesizer_Type']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(f\"\\n✅ Exported {len(df)} questions to: ./data/golden_dataset_readable.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9551336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created detailed report: ./data/golden_dataset_report.md\n"
     ]
    }
   ],
   "source": [
    "## Option 2: Create Detailed Markdown Report\n",
    "\n",
    "def create_markdown_report(golden_data, output_file='./data/golden_dataset_report.md'):\n",
    "    \"\"\"Create a detailed, human-readable markdown report of the golden dataset.\"\"\"\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"# Thudbot Golden Dataset Report\\n\\n\")\n",
    "        f.write(\"Generated synthetic test questions and answers for RAGAS evaluation.\\n\\n\")\n",
    "        f.write(f\"**Total Questions:** {len(golden_data)}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        \n",
    "        for i, item in enumerate(golden_data, 1):\n",
    "            eval_sample = item['eval_sample']\n",
    "            \n",
    "            f.write(f\"## Question {i:02d}\\n\\n\")\n",
    "            f.write(f\"**User Input:** {eval_sample.get('user_input', 'N/A')}\\n\\n\")\n",
    "            f.write(f\"**Expected Answer:**\\n{eval_sample.get('reference', 'N/A')}\\n\\n\")\n",
    "            f.write(f\"**Synthesizer:** `{item.get('synthesizer_name', 'unknown')}`\\n\\n\")\n",
    "            \n",
    "            # Add context information\n",
    "            contexts = eval_sample.get('reference_contexts', [])\n",
    "            if contexts:\n",
    "                f.write(\"**Reference Context Preview:**\\n\")\n",
    "                context_preview = str(contexts[0])[:300] + \"...\" if len(str(contexts[0])) > 300 else str(contexts[0])\n",
    "                f.write(f\"```\\n{context_preview}\\n```\\n\\n\")\n",
    "            \n",
    "            f.write(\"---\\n\\n\")\n",
    "    \n",
    "    print(f\"✅ Created detailed report: {output_file}\")\n",
    "\n",
    "# Generate the markdown report\n",
    "create_markdown_report(golden_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e7aad",
   "metadata": {},
   "source": [
    "the answers are okay, but the questions are crappy. Let's see if we can get an agent to rewrite the questions better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0010f",
   "metadata": {},
   "source": [
    "##### Five steps to re-write the questions:\n",
    "\n",
    "Define rewriter prompt\n",
    "Set up rewriter chain using rewriter prompt\n",
    "Define rewrite function that invokes rewriter_chain\n",
    "Execute the function\n",
    "Write the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee97c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question Rewriter: Transform Formal Questions → Casual Player Questions\n",
    "\n",
    "# Using the same pattern as HW7 for LLM chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13af26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create the rewriter prompt (following HW7 prompt pattern)\n",
    "QUESTION_REWRITER_PROMPT = \"\"\"\\\n",
    "You are helping rewrite questions to sound like real confused players asking for game hints.\n",
    "\n",
    "Your job is to transform formal/academic questions into casual, human-like questions that real players would ask when stuck in \"The Space Bar\" adventure game.\n",
    "\n",
    "IMPORTANT: If the question contains a question ID like \"TSB-041\" or similar, ignore that completely - it's just an organizational code that doesn't exist in the real game.\n",
    "\n",
    "Original question: {original_question}\n",
    "Game context: {context_preview}\n",
    "\n",
    "Examples of good player questions:\n",
    "- \"How do I get past the guard?\"\n",
    "- \"I'm stuck in this room, what do I do?\"\n",
    "- \"Help! I can't figure out this puzzle\"\n",
    "- \"Where's the token I need?\"\n",
    "\n",
    "Make it sound confused, or casual - like a real person, not an academic paper.\n",
    "\n",
    "Rewritten question:\"\"\"\n",
    "\n",
    "# Create the prompt template (same pattern as HW7)\n",
    "rewriter_prompt = ChatPromptTemplate.from_template(QUESTION_REWRITER_PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ba4723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM for rewriting (following HW7 pattern)\n",
    "rewriter_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# Create the rewriter chain (same LCEL pattern as HW7)\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "rewriter_chain = rewriter_prompt | rewriter_llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da4e36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main rewriting function (following HW7 iteration pattern)\n",
    "def rewrite_questions_to_player_style(golden_data):\n",
    "    \"\"\"Rewrite formal RAGAS questions to sound like casual game players\"\"\"\n",
    "    \n",
    "    updated_data = []\n",
    "    \n",
    "    print(\"🔄 Rewriting questions to sound like real players...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, item in enumerate(golden_data, 1):\n",
    "        eval_sample = item['eval_sample']\n",
    "        original_q = eval_sample.get('user_input', '')\n",
    "        \n",
    "        # Get context preview for better rewriting\n",
    "        contexts = eval_sample.get('reference_contexts', [])\n",
    "        context_preview = str(contexts[0])[:200] + \"...\" if contexts else \"No context available\"\n",
    "        \n",
    "        # Rewrite the question using our chain\n",
    "        try:\n",
    "            rewritten_q = rewriter_chain.invoke({\n",
    "                \"original_question\": original_q,\n",
    "                \"context_preview\": context_preview\n",
    "            })\n",
    "            \n",
    "            # Update the question in place\n",
    "            eval_sample['user_input'] = rewritten_q.strip()\n",
    "            eval_sample['original_question'] = original_q  # Keep original for comparison\n",
    "            \n",
    "            # Show progress\n",
    "            print(f\"✅ Question {i:02d}:\")\n",
    "            print(f\"   Original: {original_q[:70]}...\")\n",
    "            print(f\"   Rewritten: {rewritten_q.strip()[:70]}...\")\n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error rewriting question {i}: {e}\")\n",
    "            # Keep original if rewriting fails\n",
    "            eval_sample['original_question'] = original_q\n",
    "        \n",
    "        updated_data.append(item)\n",
    "    \n",
    "    print(f\"✅ Successfully rewrote {len(updated_data)} questions!\")\n",
    "    return updated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c249a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loaded 12 questions to rewrite\n",
      "🔄 Rewriting questions to sound like real players...\n",
      "--------------------------------------------------\n",
      "✅ Question 01:\n",
      "   Original: In the context of the game, what is the significance of the Yzore in r...\n",
      "   Rewritten: \"Wait, what’s the deal with the Yzore? How does it help me get to the ...\n",
      "\n",
      "✅ Question 02:\n",
      "   Original: TSB-041 what do I do?...\n",
      "   Rewritten: \"Uh, I'm kinda lost here. What am I supposed to do as Fleebix in this ...\n",
      "\n",
      "✅ Question 03:\n",
      "   Original: What UHS mean in the game?...\n",
      "   Rewritten: \"Wait, what does UHS even mean in this game?\"...\n",
      "\n",
      "✅ Question 04:\n",
      "   Original: WhaT is TSB-027?...\n",
      "   Rewritten: \"Wait, what am I supposed to do in this entry vestibule? I'm totally l...\n",
      "\n",
      "✅ Question 05:\n",
      "   Original: H0w do the residue printer and fingerprint analysis help in cracking t...\n",
      "   Rewritten: \"Hey, I'm really stuck! How do I use the residue printer and the finge...\n",
      "\n",
      "✅ Question 06:\n",
      "   Original: how use tokens for bus and find object like door or cup...\n",
      "   Rewritten: \"Hey, how do I use these tokens for the bus? And where do I even find ...\n",
      "\n",
      "✅ Question 07:\n",
      "   Original: How can you effectively utilize navigation and movement strategies wit...\n",
      "   Rewritten: \"Okay, so I'm trying to get to the Quantelope Lodge with Thud, but I h...\n",
      "\n",
      "✅ Question 08:\n",
      "   Original: How Fleebix rely on Thud and follow clues to get to Quantelope Lodge?...\n",
      "   Rewritten: \"Wait, how am I supposed to get to Quantelope Lodge with Thud? I’m rea...\n",
      "\n",
      "✅ Question 09:\n",
      "   Original: how to get to Quantelope Lodge with Thud and Fleebix, and find the tok...\n",
      "   Rewritten: \"Wait, how do I get to Quantelope Lodge with Thud and Fleebix? I need ...\n",
      "\n",
      "✅ Question 10:\n",
      "   Original: How do Fleebix and Thud get to the Quantelope Lodge, and what role doe...\n",
      "   Rewritten: \"Wait, how do Fleebix and Thud even get to the Quantelope Lodge? And w...\n",
      "\n",
      "✅ Question 11:\n",
      "   Original: How can a casual adventure gamer utilize the clues about TSB-031 and T...\n",
      "   Rewritten: \"Hey, I'm totally lost! I keep hearing about this vestibule terminal a...\n",
      "\n",
      "✅ Question 12:\n",
      "   Original: How do the TSB-031 hints about fixing or trying the terminal relate to...\n",
      "   Rewritten: \"Wait, how do the hints about fixing the terminal connect to finding T...\n",
      "\n",
      "✅ Successfully rewrote 12 questions!\n"
     ]
    }
   ],
   "source": [
    "# Execute the rewriting process\n",
    "import json\n",
    "\n",
    "# Load the original golden dataset\n",
    "with open('./data/goldendataset.json', 'r') as f:\n",
    "    original_golden_data = json.load(f)\n",
    "\n",
    "print(f\"📊 Loaded {len(original_golden_data)} questions to rewrite\")\n",
    "\n",
    "# Rewrite the questions\n",
    "rewritten_data = rewrite_questions_to_player_style(original_golden_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31116011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Created comparison report: ./data/question_rewrite_comparison.md\n",
      "💾 Saved rewritten dataset to: ./data/goldendataset_player_style.json\n",
      "\n",
      "🎯 Ready to use the player-style questions for RAGAS evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Save the rewritten dataset and create comparison report\n",
    "with open('./data/goldendataset_player_style.json', 'w') as f:\n",
    "    json.dump(rewritten_data, f, indent=2)\n",
    "\n",
    "# Create a comparison report to review the changes\n",
    "def create_comparison_report(rewritten_data, output_file='./data/question_rewrite_comparison.md'):\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"# Question Rewriting Comparison Report\\n\\n\")\n",
    "        f.write(\"Comparison of original RAGAS questions vs. player-style questions\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        \n",
    "        for i, item in enumerate(rewritten_data, 1):\n",
    "            eval_sample = item['eval_sample']\n",
    "            original = eval_sample.get('original_question', 'N/A')\n",
    "            rewritten = eval_sample.get('user_input', 'N/A')\n",
    "            \n",
    "            f.write(f\"## Question {i:02d}\\n\\n\")\n",
    "            f.write(f\"**Original (RAGAS):** {original}\\n\\n\")\n",
    "            f.write(f\"**Rewritten (Player Style):** {rewritten}\\n\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    \n",
    "    print(f\"📝 Created comparison report: {output_file}\")\n",
    "\n",
    "create_comparison_report(rewritten_data)\n",
    "print(f\"💾 Saved rewritten dataset to: ./data/goldendataset_player_style.json\")\n",
    "print(\"\\n🎯 Ready to use the player-style questions for RAGAS evaluation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908666af",
   "metadata": {},
   "source": [
    "I ran a few iterations with different prompts, and an now reasonably happy with the questions. \n",
    "\n",
    "Next step is to import the ```goldendataset_player_style.json``` for use by ragas eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15427af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load questions for testing your retrievers\n",
    "with open(\"data/goldendataset_player_style.json\", \"r\") as f:\n",
    "    golden_data = json.load(f)\n",
    "\n",
    "def run_retriever_on_dataset(name, retriever_chain, golden_data):\n",
    "    \"\"\"Run retriever and format for Ragas evaluation - consistent with your existing function\"\"\"\n",
    "    print(f\"Running {name} on golden dataset\")\n",
    "    outputs = []\n",
    "    \n",
    "    for item in golden_data:\n",
    "        question = item[\"eval_sample\"][\"user_input\"]\n",
    "        reference = item[\"eval_sample\"][\"reference\"]\n",
    "        \n",
    "        # Run your retriever\n",
    "        response = retriever_chain.invoke({\"question\": question})\n",
    "        \n",
    "        outputs.append({\n",
    "            \"user_input\": question,\n",
    "            \"reference\": reference,\n",
    "            \"response\": response[\"response\"].content if hasattr(response[\"response\"], \"content\") else response[\"response\"],\n",
    "            \"retrieved_contexts\": [ctx.page_content for ctx in response[\"context\"]],\n",
    "            \"retriever_name\": name\n",
    "        })\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017455bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cb2736",
   "metadata": {},
   "source": [
    "## Step 4: RAG Chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc850ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1274cae5",
   "metadata": {},
   "source": [
    "### R - Retrieval\n",
    "\n",
    "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
    "\n",
    "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a67ec143",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd769b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
